# üìã Estado de Sesi√≥n - Handover

**Fecha:** 2026-01-03
**Objetivo:** Refactor Pipeline Incremental + Nuclear Test
**Estado:** üõë PAUSADO (VM Apagada)

## ‚úÖ Logros Hoy
1. **Infraestructura Reparada:**
   - Se aument√≥ memoria de Docker (Scheduler 10GB, Spark 4GB) para evitar `OOM Killed`.
   - Se corrigieron permisos en `data/` y `logs/`.
2. **C√≥digo Listo:**
   - Refactor `silver_*.py` y `gold_*.py` a incremental terminados.
   - Watermark global implementado.
3. **Datos:**
   - "Opci√≥n Nuclear" ejecutada (GCS limpio).
   - Tareas `repartition_raw` exitosas.

## ‚è≠Ô∏è Pasos para la Siguiente Sesi√≥n
La VM `airflow-server-prod` est√° **APAGADA**. Al iniciar:

1. **Encender VM:**
   ```bash
   gcloud compute instances start airflow-server-prod --zone=us-central1-a --project=salvando-patitas-de-spark
   ```

2. **Reanudar Pipeline:**
   Conectarse por SSH y limpiar la tarea fallida (que fall√≥ por memoria antes del fix) para que reintente con los 10GB nuevos.
   ```bash
   # Esperar a que Docker inicie (appx 1 min)
   docker exec data-plataform-fsp-spark-airflow_airflow-scheduler_1 airflow tasks clear spdp_data_platform_main -t silver_donantes -d -y
   ```

3. **Validaci√≥n:**
   - Esperar que el DAG termine (deber√≠a ser r√°pido con la nueva RAM).
   - Verificar creaci√≥n de `gs://salvando-patitas-spark/state/watermarks.json`.
   - Verificar datos en BigQuery.

4. **Apagar:**
   - El DAG tiene un task `stop_instance` al final, as√≠ que **deber√≠a apagarse sola** si todo sale bien. Si falla, apagar manual.
