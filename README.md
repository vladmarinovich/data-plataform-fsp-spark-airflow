# ğŸ¾ Salvando Patitas - Data Platform (PySpark + Airflow)

Pipeline de datos cloud-agnostic usando Apache Spark y Apache Airflow para procesamiento ETL de datos de rescate animal.

## ğŸ—ï¸ Arquitectura

```
Supabase (Transactional DB) 
    â†“
Extract (Pandas - rÃ¡pido)
    â†“
Raw Layer (Parquet)
    â†“
Silver Layer (Spark - Data Quality + Transformaciones)
    â†“
Gold Layer (Spark - Dimensiones + Hechos + Features)
    â†“
BigQuery (AnÃ¡lisis/BI) [TODO]
```

## ğŸ“Š Estado Actual

### âœ… Funcionando
- **ExtracciÃ³n**: 6 tablas desde raw mock data (5 segundos)
- **Silver Layer**: 6 transformations con Data Quality Assertions
- **Gold Layer**: Dimensiones, Hechos, Features, Dashboards
- **OrquestaciÃ³n**: Airflow con DAG completo
- **Cuarentena**: Sistema de quarantine para datos invÃ¡lidos

### âš ï¸ Issues Conocidos

**Performance Local (Docker + Spark):**
- **Tiempo actual**: ~27 minutos end-to-end
- **Tiempo esperado en cloud**: 5-10 minutos
- **Problema**: Overhead de Spark para datasets pequeÃ±os en laptop

**ConfiguraciÃ³n Actual:**
- RAM: 8GB Docker
- Spark Driver: 3GB
- Spark Executor: 3GB
- Shuffle Partitions: 8
- Cores: local[2]

### ğŸ“ Optimizaciones Aplicadas

```python
# jobs/utils/spark_session.py
.config("spark.sql.shuffle.partitions", "8")  # Default: 200
.config("spark.default.parallelism", "4")     # Reduce overhead
.config("spark.serializer", "org.apache.spark.serializer.KryoSerializer")
.config("spark.sql.adaptive.enabled", "true")
```

## ğŸš€ Quick Start

### Prerequisitos
```bash
docker
docker-compose
Python 3.11+
```

### Levantar Ambiente Local
```bash
# 1. Levantar Airflow + PostgreSQL
docker compose up -d

# 2. Acceder a Airflow UI
open http://localhost:8080
# Usuario: admin
# Password: admin

# 3. Trigger DAG manualmente
# Click en "spdp_data_platform_main" â†’ Trigger
```

## ğŸ“ Estructura del Proyecto

```
â”œâ”€â”€ config/              # ConfiguraciÃ³n global (paths, Spark, etc)
â”œâ”€â”€ dags/                # Airflow DAGs
â”‚   â””â”€â”€ spdp_main_pipeline.py
â”œâ”€â”€ jobs/
â”‚   â”œâ”€â”€ silver/         # Transformaciones Silver + DQ
â”‚   â”œâ”€â”€ gold/           # Agregaciones Gold
â”‚   â””â”€â”€ utils/          # Spark session, helpers
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ quick_mock_data.py      # Generador de datos mock (Pandas)
â”‚   â””â”€â”€ inspect_quarantine.py   # Revisar datos rechazados
â””â”€â”€ data/
    â””â”€â”€ lake/
        â”œâ”€â”€ raw/        # Bronze layer (Parquet)
        â”œâ”€â”€ silver/     # Silver layer (Parquet)
        â”œâ”€â”€ gold/       # Gold layer (Parquet)
        â””â”€â”€ quarantine/ # DQ rejected records
```

## ğŸ›¡ï¸ Data Quality

Implementado en Silver Layer:

**Donaciones:**
- Email vÃ¡lido (contiene @)
- ID no nulo
- Fecha posterior a 2010

**Casos:**
- ID no nulo
- Fecha ingreso vÃ¡lida (2010-hoy)
- Nombre no default

**Hogares:**
- Cupo no negativo
- Tarifa no negativa
- Nombre obligatorio

Registros que fallan â†’ `data/lake/quarantine/{table}/`

## ğŸ¯ PrÃ³ximos Pasos Sugeridos

### 1. **Performance** (CRÃTICO)
- [ ] Evaluar deployment a Google Cloud Dataproc
- [ ] Considerar dbt para transformaciones simples
- [ ] Profile Spark jobs para identificar bottlenecks

### 2. **BigQuery Integration**
- [ ] Agregar carga de Gold â†’ BigQuery
- [ ] Configurar external tables en GCS
- [ ] Automatizar schema sync

### 3. **Monitoring**
- [ ] Agregar mÃ©tricas de calidad de datos
- [ ] Dashboard de ejecuciÃ³n en Airflow
- [ ] Alertas de fallo

## ğŸ¤ Para Reviewers

**Pregunta principal**: 
> Â¿CÃ³mo optimizar tiempos de ejecuciÃ³n para datasets < 1000 registros sin sacrificar la arquitectura Spark/Airflow?

**Contexto**:
- Objetivo: Pipeline production-ready para portafolio
- Datasets actuales: 50-200 registros por tabla
- Growth esperado: 50K+ registros
- Must-have: Spark (skill requerido para vacantes)

**Ãreas de review**:
1. ConfiguraciÃ³n de Spark (Â¿sobrecarga innecesaria?)
2. Estrategia de particionamiento
3. Alternativas hÃ­bridas (Pandas en local, Spark en cloud)
4. Arquitectura de DAG (Â¿dependencias optimizadas?)

---

## ğŸ“š Stack TecnolÃ³gico

- **OrquestaciÃ³n**: Apache Airflow 2.10
- **Procesamiento**: Apache Spark 3.5 (PySpark)
- **Storage**: Parquet (columnar)
- **BD Transaccional**: Supabase (PostgreSQL)
- **Metadata**: Airflow PostgreSQL
- **Cloud Target**: Google Cloud (Dataproc + Composer + BigQuery)

## ğŸ“„ Licencia

MIT
