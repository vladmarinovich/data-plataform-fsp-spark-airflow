# üéØ ACTUALIZACI√ìN: Extracci√≥n Real desde Supabase

## ‚úÖ Cambios Implementados

### üìÑ Archivos Nuevos Creados

1. **`scripts/extract_from_supabase.py`** (300+ l√≠neas)
   - Script principal de extracci√≥n desde Supabase
   - Manejo de watermarks (estado incremental)
   - Extracci√≥n incremental (donaciones, gastos)
   - Extracci√≥n snapshot (donantes, casos, proveedores)
   - Escritura a Bronze layer en Parquet

2. **`docs/EXTRACCION_SUPABASE.md`**
   - Gu√≠a completa de extracci√≥n
   - Configuraci√≥n de credenciales
   - Ejemplos de ejecuci√≥n
   - Troubleshooting detallado

3. **`docs/QUICKSTART.md`** (actualizado)
   - Gu√≠a paso a paso con datos reales
   - Configuraci√≥n de Supabase
   - Verificaci√≥n de resultados

### üîß Archivos Modificados

1. **`scripts/setup.sh`**
   - Ahora pregunta si usar datos mock o reales
   - Valida credenciales de Supabase
   - Ejecuta extracci√≥n autom√°ticamente si est√° configurado

2. **`.gitignore`**
   - Agregado `watermarks.json` (estado de extracci√≥n)

---

## üîÑ Flujo Actualizado

### Antes (Solo Mock)
```
scripts/generate_mock_data.py
    ‚Üì
data/raw/donaciones_mock.parquet
    ‚Üì
jobs/transform_donations.py
```

### Ahora (Real + Mock)
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Opci√≥n A: Datos REALES         ‚îÇ
‚îÇ  scripts/extract_from_supabase  ‚îÇ
‚îÇ         ‚Üì                        ‚îÇ
‚îÇ  data/raw/donaciones.parquet    ‚îÇ
‚îÇ  data/raw/gastos.parquet        ‚îÇ
‚îÇ  data/raw/donantes.parquet      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Opci√≥n B: Datos MOCK           ‚îÇ
‚îÇ  scripts/generate_mock_data.py  ‚îÇ
‚îÇ         ‚Üì                        ‚îÇ
‚îÇ  data/raw/donaciones_mock.parquet‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

         ‚Üì (ambas opciones)
         
jobs/transform_donations.py
    ‚Üì
data/processed/silver/donaciones/
    ‚Üì
data/output/gold/donaciones_monthly/
```

---

## üöÄ C√≥mo Usar (Paso a Paso)

### 1. Setup Inicial
```bash
cd pyspark-airflow-data-platform
./scripts/setup.sh
```

### 2. Configurar Supabase
```bash
nano .env

# Editar:
SUPABASE_URL=https://tu-proyecto.supabase.co
SUPABASE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
```

### 3. Extraer Datos Reales
```bash
source venv/bin/activate
python scripts/extract_from_supabase.py
```

### 4. Transformar con PySpark
```bash
spark-submit --master local[*] jobs/transform_donations.py
```

---

## üìä Caracter√≠sticas de la Extracci√≥n

### ‚úÖ Extracci√≥n Incremental (Watermarks)

**Tablas**: `donaciones`, `gastos`

**C√≥mo funciona**:
1. Lee `watermarks.json` (√∫ltima fecha procesada)
2. Query: `SELECT * WHERE fecha > watermark`
3. Escribe nuevos datos en modo `append`
4. Actualiza watermark con MAX(fecha)

**Ejemplo**:
```json
// watermarks.json
{
  "donaciones": "2024-12-25",
  "gastos": "2024-12-20"
}
```

**Ventajas**:
- Solo extrae datos nuevos
- Eficiente (no procesa todo cada vez)
- Idempotente (se puede re-ejecutar)

### ‚úÖ Extracci√≥n Snapshot (Full Load)

**Tablas**: `donantes`, `casos`, `proveedores`

**C√≥mo funciona**:
1. Query: `SELECT *` (todos los registros)
2. Escribe en modo `overwrite`
3. No usa watermarks

**Cu√°ndo usar**:
- Tablas maestras (cambian poco)
- Tablas peque√±as
- Necesitas estado completo

---

## üîç Validaci√≥n

### Verificar extracci√≥n exitosa:

```bash
# Ver archivos generados
ls -lh data/raw/

# Deber√≠a mostrar:
# donaciones.parquet
# gastos.parquet
# donantes.parquet
# casos.parquet
# proveedores.parquet

# Ver watermarks
cat watermarks.json

# Deber√≠a mostrar:
# {
#   "donaciones": "2024-12-26",
#   "gastos": "2024-12-25"
# }
```

### Inspeccionar datos:

```python
import pandas as pd

# Leer Parquet
df = pd.read_parquet("data/raw/donaciones.parquet")

# Verificar
print(f"Registros: {len(df)}")
print(f"Columnas: {df.columns.tolist()}")
print(f"Fechas: {df['fecha_donacion'].min()} a {df['fecha_donacion'].max()}")
print(f"Total donado: ${df['monto'].sum():,.2f}")
```

---

## üéØ Ventajas del Nuevo Sistema

### 1. Datos Reales
- ‚úÖ Conecta directamente a Supabase
- ‚úÖ No necesitas generar datos mock
- ‚úÖ Pruebas con datos de producci√≥n

### 2. Incremental
- ‚úÖ Solo extrae datos nuevos
- ‚úÖ Eficiente en tiempo y recursos
- ‚úÖ Watermarks autom√°ticos

### 3. Flexible
- ‚úÖ Puedes usar mock para testing
- ‚úÖ Puedes usar real para desarrollo
- ‚úÖ Mismo c√≥digo PySpark para ambos

### 4. Mantenible
- ‚úÖ C√≥digo reutilizado del CRM original
- ‚úÖ Patrones probados en producci√≥n
- ‚úÖ F√°cil de extender a m√°s tablas

---

## üìù Configuraci√≥n Avanzada

### Agregar m√°s tablas incrementales:

Editar `config/__init__.py`:
```python
INCREMENTAL_TABLES = {
    "donaciones": "fecha_donacion",
    "gastos": "fecha_gasto",
    "adopciones": "fecha_adopcion",  # Nueva
}
```

### Agregar m√°s tablas snapshot:

```python
FULL_LOAD_TABLES = [
    "donantes",
    "casos",
    "proveedores",
    "veterinarias",  # Nueva
]
```

### Resetear watermarks:

```bash
# Opci√≥n 1: Eliminar archivo
rm watermarks.json

# Opci√≥n 2: Resetear tabla espec√≠fica
python -c "
import json
with open('watermarks.json', 'r') as f:
    w = json.load(f)
w['donaciones'] = '2020-01-01'
with open('watermarks.json', 'w') as f:
    json.dump(w, f, indent=2)
"
```

---

## üîó Documentaci√≥n Relacionada

- **Gu√≠a de extracci√≥n**: [`docs/EXTRACCION_SUPABASE.md`](docs/EXTRACCION_SUPABASE.md)
- **Inicio r√°pido**: [`docs/QUICKSTART.md`](docs/QUICKSTART.md)
- **Arquitectura**: [`docs/ARCHITECTURE.md`](docs/ARCHITECTURE.md)

---

## ‚úÖ Checklist de Migraci√≥n

Si ya ten√≠as el proyecto con datos mock:

- [ ] Ejecutar `./scripts/setup.sh` de nuevo
- [ ] Configurar credenciales en `.env`
- [ ] Ejecutar `python scripts/extract_from_supabase.py`
- [ ] Verificar archivos en `data/raw/`
- [ ] Ejecutar job PySpark
- [ ] Verificar resultados en `data/processed/` y `data/output/`

---

## üéâ Resultado Final

Ahora tienes:
- ‚úÖ Extracci√≥n autom√°tica desde Supabase
- ‚úÖ Watermarks para procesamiento incremental
- ‚úÖ Bronze layer con datos reales
- ‚úÖ Transformaciones PySpark funcionando
- ‚úÖ Silver y Gold layers generados
- ‚úÖ Opci√≥n de usar mock para testing

**¬°El proyecto est√° listo para trabajar con datos reales!** üöÄ

---

**Fecha de actualizaci√≥n**: 2024-12-26  
**Versi√≥n**: 2.0.0 (Extracci√≥n Real)
