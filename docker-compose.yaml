version: '3.8'
services:
  postgres:
    image: postgres:13
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U airflow" ]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data

  airflow-setup:
    build: .
    depends_on:
      - postgres
    deploy:
      resources:
        limits:
          memory: 512M
    volumes:
      - .:/opt/airflow
      - ~/.config/gcloud:/home/airflow/.config/gcloud:ro
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_KEY=${SUPABASE_KEY}
      - GOOGLE_APPLICATION_CREDENTIALS=/home/airflow/.config/gcloud/application_default_credentials.json
    entrypoint: >
      bash -c "airflow db init && airflow users create --username admin --firstname Vlad --lastname Marinovich --role Admin --email admin@spdp.com --password admin || true"

  airflow-scheduler:
    build: .
    restart: always
    depends_on:
      postgres:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 2560M
        reservations:
          memory: 1536M
    volumes:
      - .:/opt/airflow
      - ~/.config/gcloud:/home/airflow/.config/gcloud:ro
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__PARALLELISM=2
      - AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG=2
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_KEY=${SUPABASE_KEY}
      - GOOGLE_APPLICATION_CREDENTIALS=/home/airflow/.config/gcloud/application_default_credentials.json
      - ENV=cloud
      # Configuraci√≥n de Spark para bajo consumo de memoria
      - SPARK_DRIVER_MEMORY=1g
      - SPARK_EXECUTOR_MEMORY=1g
    command: scheduler

  airflow-webserver:
    build: .
    restart: always
    depends_on:
      postgres:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 2048M
        reservations:
          memory: 1024M
    volumes:
      - .:/opt/airflow
      - ~/.config/gcloud:/home/airflow/.config/gcloud:ro
    ports:
      - "8080:8080"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__WEBSERVER__SECRET_KEY=spdp_secret_key
      - AIRFLOW__WEBSERVER__WORKERS=2
      - AIRFLOW__WEBSERVER__WEB_SERVER_WORKER_TIMEOUT=600
      - AIRFLOW__CORE__DAGBAG_IMPORT_TIMEOUT=600
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_KEY=${SUPABASE_KEY}
      - GOOGLE_APPLICATION_CREDENTIALS=/home/airflow/.config/gcloud/application_default_credentials.json
      - ENV=cloud
    command: webserver

volumes:
  postgres-db-volume:
