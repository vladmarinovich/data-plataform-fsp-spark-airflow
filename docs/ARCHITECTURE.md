# ğŸ—ï¸ Arquitectura del Proyecto

## VisiÃ³n General

Este proyecto implementa un **Data Pipeline Cloud-Agnostic** basado en:

- **Apache Spark**: Procesamiento distribuido de datos
- **Apache Airflow**: OrquestaciÃ³n y scheduling
- **Medallion Architecture**: Bronze â†’ Silver â†’ Gold
- **Python**: Lenguaje principal para ETL

---

## Arquitectura de Capas

### 1. Bronze Layer (Raw Data)
**PropÃ³sito**: Almacenar datos crudos sin transformar

- **Formato**: Parquet (compresiÃ³n Snappy)
- **Fuente**: APIs, Bases de datos, Archivos
- **CaracterÃ­sticas**:
  - Datos tal cual vienen de la fuente
  - Inmutables (append-only)
  - Particionados por fecha de ingesta

**Ejemplo**:
```
data/raw/
  â””â”€â”€ donaciones_mock.parquet
```

### 2. Silver Layer (Cleaned Data)
**PropÃ³sito**: Datos limpios y estandarizados

- **Formato**: Parquet particionado
- **Transformaciones**:
  - ValidaciÃ³n de esquema
  - ConversiÃ³n de tipos
  - Manejo de nulos
  - DeduplicaciÃ³n
  - Columnas derivadas (aÃ±o, mes, dÃ­a)

**Ejemplo**:
```
data/processed/silver/donaciones/
  â”œâ”€â”€ anio=2023/
  â”‚   â”œâ”€â”€ mes=01/
  â”‚   â””â”€â”€ mes=02/
  â””â”€â”€ anio=2024/
      â””â”€â”€ mes=01/
```

### 3. Gold Layer (Business Aggregations)
**PropÃ³sito**: MÃ©tricas de negocio listas para consumo

- **Formato**: Parquet o Delta Lake
- **Transformaciones**:
  - Agregaciones por dimensiones
  - CÃ¡lculos de KPIs
  - Joins con dimensiones
  - Optimizado para queries analÃ­ticos

**Ejemplo**:
```
data/output/gold/
  â””â”€â”€ donaciones_monthly/
      â””â”€â”€ part-00000.parquet
```

---

## Flujo de Datos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚
â”‚  (Supabase/API) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Extract Script â”‚  â† Python + Pandas
â”‚   (Python)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Bronze Layer   â”‚  â† Parquet (Raw)
â”‚   (Raw Data)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PySpark Job    â”‚  â† Transformaciones
â”‚  (Silver ETL)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Silver Layer   â”‚  â† Parquet Particionado
â”‚ (Cleaned Data)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PySpark Job    â”‚  â† Agregaciones
â”‚   (Gold ETL)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Gold Layer    â”‚  â† MÃ©tricas de Negocio
â”‚ (Aggregations)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BI Tools /     â”‚
â”‚  Analytics      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Componentes Principales

### 1. Config (`config/`)
Centraliza configuraciÃ³n por entorno:
- Paths de datos
- Credenciales (via .env)
- Constantes de negocio
- ConfiguraciÃ³n de Spark

### 2. Jobs (`jobs/`)
Scripts PySpark para transformaciones:
- `transform_donations.py`: Pipeline principal
- `utils/spark_session.py`: Factory de SparkSession
- `utils/data_quality.py`: Validaciones

### 3. DAGs (`dags/`)
Definiciones de Airflow para orquestaciÃ³n:
- Scheduling diario/horario
- Dependencias entre jobs
- Manejo de errores y retries

### 4. Scripts (`scripts/`)
Utilidades de desarrollo:
- `setup.sh`: InicializaciÃ³n del proyecto
- `generate_mock_data.py`: Datos de prueba

---

## Patrones de DiseÃ±o

### 1. Idempotencia
Todos los jobs pueden ejecutarse mÃºltiples veces sin efectos secundarios:
- Uso de `mode("overwrite")` con particiones
- Watermarks para procesamiento incremental
- DeduplicaciÃ³n basada en claves primarias

### 2. Particionamiento
OptimizaciÃ³n de queries mediante particiones:
```python
df.write.partitionBy("anio", "mes").parquet(path)
```

### 3. Schema Evolution
Manejo de cambios en esquemas:
- ValidaciÃ³n de columnas requeridas
- Columnas opcionales con defaults
- Versionado de esquemas

### 4. Data Quality
Validaciones en mÃºltiples capas:
- Bronze: ValidaciÃ³n bÃ¡sica de formato
- Silver: ValidaciÃ³n de negocio
- Gold: ValidaciÃ³n de mÃ©tricas

---

## ConfiguraciÃ³n de Spark

### Local Development
```python
spark = SparkSession.builder \
    .master("local[*]") \
    .config("spark.driver.memory", "2g") \
    .config("spark.executor.memory", "2g") \
    .getOrCreate()
```

### Production (Cloud)
```python
spark = SparkSession.builder \
    .master("yarn") \  # o "k8s://..." para Kubernetes
    .config("spark.executor.instances", "10") \
    .config("spark.executor.cores", "4") \
    .config("spark.executor.memory", "8g") \
    .getOrCreate()
```

---

## Estrategias de Deployment

### 1. Local (Desarrollo)
- Spark standalone mode
- Datos en filesystem local
- Airflow en modo standalone

### 2. AWS
- EMR para Spark jobs
- S3 para data lake
- MWAA para Airflow
- Glue Catalog para metastore

### 3. GCP
- Dataproc para Spark jobs
- GCS para data lake
- Cloud Composer para Airflow
- BigQuery como warehouse

### 4. Azure
- HDInsight para Spark jobs
- Azure Blob Storage para data lake
- Azure Data Factory para orquestaciÃ³n
- Synapse Analytics como warehouse

---

## Monitoreo y Observabilidad

### MÃ©tricas Clave
- Tiempo de ejecuciÃ³n por job
- Cantidad de registros procesados
- Errores y retries
- Uso de recursos (CPU, memoria)

### Logging
```python
import logging
logger = logging.getLogger(__name__)
logger.info("Procesando 1000 registros...")
```

### Alertas
- Jobs fallidos
- Latencia excesiva
- Calidad de datos degradada

---

## Mejores PrÃ¡cticas

### 1. CÃ³digo
- âœ… Usar type hints en Python
- âœ… Documentar con docstrings
- âœ… Tests unitarios para transformaciones
- âœ… Linting con Black y Flake8

### 2. Datos
- âœ… Particionamiento por fecha
- âœ… CompresiÃ³n (Snappy para Parquet)
- âœ… Evitar small files problem
- âœ… Usar columnar formats (Parquet, ORC)

### 3. Performance
- âœ… Broadcast joins para tablas pequeÃ±as
- âœ… Repartitioning antes de writes
- âœ… Caching de DataFrames reutilizados
- âœ… Adaptive Query Execution (AQE)

---

## Referencias

- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture)
- [Apache Airflow Best Practices](https://airflow.apache.org/docs/apache-airflow/stable/best-practices.html)
