# ðŸ”„ GuÃ­a de ExtracciÃ³n desde Supabase

## ðŸ“‹ Resumen

Este documento explica cÃ³mo extraer datos **reales** desde Supabase en lugar de usar datos mock.

---

## ðŸŽ¯ Diferencias: Mock vs Real

### Flujo Anterior (Mock)
```
scripts/generate_mock_data.py
    â†“
data/raw/donaciones_mock.parquet
    â†“
jobs/transform_donations.py
```

### Flujo Nuevo (Real)
```
scripts/extract_from_supabase.py
    â†“
data/raw/donaciones.parquet
data/raw/gastos.parquet
data/raw/donantes.parquet
    â†“
jobs/transform_donations.py
```

---

## âš™ï¸ ConfiguraciÃ³n Inicial

### 1. Editar archivo `.env`

```bash
# Abrir archivo .env
nano .env
```

Configurar credenciales de Supabase:
```bash
SUPABASE_URL=https://xxxxxxxxxxx.supabase.co
SUPABASE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
```

**Â¿DÃ³nde encontrar estas credenciales?**
1. Ir a [Supabase Dashboard](https://app.supabase.com)
2. Seleccionar tu proyecto
3. Settings â†’ API
4. Copiar:
   - **URL**: Project URL
   - **Key**: `anon` `public` key

### 2. Verificar conexiÃ³n

```bash
# Activar entorno virtual
source venv/bin/activate

# Probar conexiÃ³n
python -c "
from supabase import create_client
import os
from dotenv import load_dotenv

load_dotenv()
client = create_client(os.getenv('SUPABASE_URL'), os.getenv('SUPABASE_KEY'))
print('âœ… ConexiÃ³n exitosa a Supabase')
"
```

---

## ðŸš€ ExtracciÃ³n de Datos

### EjecuciÃ³n Manual

```bash
# Activar entorno virtual
source venv/bin/activate

# Ejecutar extracciÃ³n
python scripts/extract_from_supabase.py
```

### QuÃ© hace el script

#### 1. Carga Watermarks
```
ðŸ“‚ Busca archivo: watermarks.json
   Si existe: Lee Ãºltima fecha procesada por tabla
   Si no existe: Usa fecha default "2020-01-01"
```

#### 2. ExtracciÃ³n Incremental
```
Para cada tabla incremental (donaciones, gastos):
  1. Lee watermark actual
  2. Query: SELECT * WHERE fecha > watermark
  3. Guarda en data/raw/{tabla}.parquet (modo append)
  4. Calcula nuevo watermark (MAX fecha)
  5. Actualiza watermarks.json
```

#### 3. ExtracciÃ³n Snapshot
```
Para cada tabla snapshot (donantes, casos, proveedores):
  1. Query: SELECT * (todos los registros)
  2. Guarda en data/raw/{tabla}.parquet (modo overwrite)
```

---

## ðŸ“Š Ejemplo de EjecuciÃ³n

### Primera EjecuciÃ³n (Sin watermarks)

```bash
$ python scripts/extract_from_supabase.py

============================================================
ðŸ Iniciando ExtracciÃ³n desde Supabase
   Timestamp: 2024-12-26 10:30:00
============================================================
âœ… Conectado a Supabase: https://xxxxx.supabase.co
âš ï¸  No existe archivo de watermarks, creando nuevo...

============================================================
ðŸš€ EXTRACCIÃ“N INCREMENTAL
============================================================

ðŸ“¥ Extrayendo tabla 'donaciones' (incremental)...
   Watermark actual: 2020-01-01
   âœ… ExtraÃ­dos 1543 registros nuevos
   Rango de fechas: 2023-01-15 a 2024-12-25

ðŸ’¾ Escribiendo a Bronze layer: data/raw/donaciones.parquet
   Modo: append
   âœ… Escritura completa: 1543 registros
   ðŸ“Š Nuevo watermark: 2024-12-25

ðŸ“¥ Extrayendo tabla 'gastos' (incremental)...
   Watermark actual: 2020-01-01
   âœ… ExtraÃ­dos 892 registros nuevos
   Rango de fechas: 2023-02-10 a 2024-12-20

ðŸ’¾ Escribiendo a Bronze layer: data/raw/gastos.parquet
   Modo: append
   âœ… Escritura completa: 892 registros
   ðŸ“Š Nuevo watermark: 2024-12-20

============================================================
ðŸ“¸ EXTRACCIÃ“N SNAPSHOT
============================================================

ðŸ“¸ Extrayendo tabla 'donantes' (snapshot completo)...
   âœ… ExtraÃ­dos 234 registros totales

ðŸ’¾ Escribiendo a Bronze layer: data/raw/donantes.parquet
   Modo: overwrite
   âœ… Escritura completa: 234 registros

âœ… Watermarks guardados: {
  "donaciones": "2024-12-25",
  "gastos": "2024-12-20"
}

============================================================
âœ… ExtracciÃ³n completada exitosamente
============================================================

ðŸ’¡ Siguiente paso:
   spark-submit --master local[*] jobs/transform_donations.py
```

### Segunda EjecuciÃ³n (Con watermarks)

```bash
$ python scripts/extract_from_supabase.py

============================================================
ðŸ Iniciando ExtracciÃ³n desde Supabase
============================================================
âœ… Conectado a Supabase: https://xxxxx.supabase.co
âœ… Watermarks cargados: {
  "donaciones": "2024-12-25",
  "gastos": "2024-12-20"
}

============================================================
ðŸš€ EXTRACCIÃ“N INCREMENTAL
============================================================

ðŸ“¥ Extrayendo tabla 'donaciones' (incremental)...
   Watermark actual: 2024-12-25
   âœ… ExtraÃ­dos 5 registros nuevos
   Rango de fechas: 2024-12-26 a 2024-12-26

ðŸ’¾ Escribiendo a Bronze layer: data/raw/donaciones.parquet
   Modo: append
   âœ… Append exitoso: +5 registros nuevos
   Total en Bronze: 1548 registros
   ðŸ“Š Nuevo watermark: 2024-12-26

ðŸ“¥ Extrayendo tabla 'gastos' (incremental)...
   Watermark actual: 2024-12-20
   âš ï¸  No hay datos nuevos

============================================================
âœ… ExtracciÃ³n completada exitosamente
============================================================
```

---

## ðŸ“ Archivos Generados

### Estructura despuÃ©s de extracciÃ³n:

```
data/raw/
â”œâ”€â”€ donaciones.parquet      # Datos incrementales (append)
â”œâ”€â”€ gastos.parquet          # Datos incrementales (append)
â”œâ”€â”€ donantes.parquet        # Snapshot (overwrite)
â”œâ”€â”€ casos.parquet           # Snapshot (overwrite)
â””â”€â”€ proveedores.parquet     # Snapshot (overwrite)

watermarks.json             # Estado de Ãºltima extracciÃ³n
```

### Contenido de `watermarks.json`:

```json
{
  "donaciones": "2024-12-26",
  "gastos": "2024-12-20"
}
```

---

## ðŸ”§ ConfiguraciÃ³n Avanzada

### Agregar mÃ¡s tablas

Editar `config/__init__.py`:

```python
# Tablas incrementales (append-only)
INCREMENTAL_TABLES = {
    "donaciones": "fecha_donacion",
    "gastos": "fecha_gasto",
    "adopciones": "fecha_adopcion",  # Nueva tabla
}

# Tablas snapshot (full overwrite)
FULL_LOAD_TABLES = [
    "donantes",
    "casos",
    "proveedores",
    "veterinarias",  # Nueva tabla
]
```

### Resetear watermarks

```bash
# OpciÃ³n 1: Eliminar archivo
rm watermarks.json

# OpciÃ³n 2: Editar manualmente
nano watermarks.json
# Cambiar fechas a "2020-01-01"

# OpciÃ³n 3: Resetear una tabla especÃ­fica
python -c "
import json
with open('watermarks.json', 'r') as f:
    w = json.load(f)
w['donaciones'] = '2020-01-01'
with open('watermarks.json', 'w') as f:
    json.dump(w, f, indent=2)
"
```

---

## ðŸ› Troubleshooting

### Error: "Faltan credenciales de Supabase"

**SoluciÃ³n**:
```bash
# Verificar que .env tenga las variables
cat .env | grep SUPABASE

# DeberÃ­a mostrar:
# SUPABASE_URL=https://...
# SUPABASE_KEY=eyJ...
```

### Error: "Connection refused" o "Unauthorized"

**Causas posibles**:
1. URL incorrecta
2. API Key incorrecta
3. Proyecto pausado en Supabase
4. Firewall bloqueando conexiÃ³n

**SoluciÃ³n**:
```bash
# Verificar URL y Key en Supabase Dashboard
# Settings â†’ API â†’ Project URL y anon/public key
```

### Error: "Table does not exist"

**Causa**: La tabla no existe en Supabase

**SoluciÃ³n**:
```bash
# Verificar tablas disponibles
python -c "
from supabase import create_client
import os
from dotenv import load_dotenv

load_dotenv()
client = create_client(os.getenv('SUPABASE_URL'), os.getenv('SUPABASE_KEY'))

# Listar tablas (requiere permisos)
response = client.table('donaciones').select('*').limit(1).execute()
print('âœ… Tabla donaciones existe')
"
```

### No se extraen datos nuevos

**Causa**: Watermark estÃ¡ adelantado

**SoluciÃ³n**:
```bash
# Ver watermarks actuales
cat watermarks.json

# Resetear si es necesario
rm watermarks.json
```

---

## ðŸ”„ IntegraciÃ³n con PySpark

### Flujo completo:

```bash
# 1. Extraer datos de Supabase
python scripts/extract_from_supabase.py

# 2. Transformar con PySpark
spark-submit --master local[*] jobs/transform_donations.py

# 3. Verificar resultados
ls -lh data/processed/silver/donaciones/
ls -lh data/output/gold/donaciones_monthly/
```

### AutomatizaciÃ³n con cron:

```bash
# Editar crontab
crontab -e

# Agregar ejecuciÃ³n diaria a las 2 AM
0 2 * * * cd /path/to/project && source venv/bin/activate && python scripts/extract_from_supabase.py && spark-submit --master local[*] jobs/transform_donations.py
```

---

## ðŸ“ Mejores PrÃ¡cticas

### 1. Backup de watermarks
```bash
# Antes de resetear, hacer backup
cp watermarks.json watermarks.backup.json
```

### 2. Logs de extracciÃ³n
```bash
# Guardar logs
python scripts/extract_from_supabase.py 2>&1 | tee logs/extract_$(date +%Y%m%d_%H%M%S).log
```

### 3. Validar datos extraÃ­dos
```python
import pandas as pd

# Leer y validar
df = pd.read_parquet("data/raw/donaciones.parquet")
print(f"Registros: {len(df)}")
print(f"Rango fechas: {df['fecha_donacion'].min()} a {df['fecha_donacion'].max()}")
print(f"Nulos: {df.isnull().sum()}")
```

---

## ðŸŽ¯ PrÃ³ximos Pasos

1. âœ… Configurar credenciales en `.env`
2. âœ… Ejecutar primera extracciÃ³n
3. âœ… Verificar archivos en `data/raw/`
4. âœ… Ejecutar transformaciÃ³n PySpark
5. ðŸ”„ Configurar Airflow para automatizar

---

**DocumentaciÃ³n actualizada**: 2024-12-26
