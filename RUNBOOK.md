# üöí SPDP Runbook de Operaciones

Este documento detalla los procedimientos operativos est√°ndar y resoluci√≥n de problemas para la **Salvando Patitas Data Platform**.

---

## üö® Procedimientos de Emergencia

### 1. El Pipeline Fall√≥ y no se recupera
Si Airflow reintent√≥ 3 veces y sigue fallando:

1.  **Conectarse a la VM:**
    ```bash
    gcloud compute ssh airflow-server-prod --zone=us-central1-a -- -L 8080:localhost:8080
    ```
2.  **Revisar Logs de Docker:**
    ```bash
    cd ~/data-plataform-fsp-spark-airflow
    docker compose -f docker-compose.prod.yaml logs -f --tail=100 scheduler
    ```
3.  **Reiniciar Servicios (Soft Reset):**
    ```bash
    docker compose -f docker-compose.prod.yaml restart
    ```
4.  **Reinicio Total (Hard Reset - Si nada funciona):**
    ```bash
    docker compose -f docker-compose.prod.yaml down
    docker compose -f docker-compose.prod.yaml up -d
    ```

---

## üõ†Ô∏è Troubleshooting (Soluci√≥n de Problemas)

### Error: `java.lang.OutOfMemoryError (OOM)`
*   **S√≠ntoma:** El job de Spark muere s√∫bitamente o el contenedor se reinicia.
*   **Causa:** La VM de 16GB se qued√≥ sin RAM porque corrieron m√°s de 2 jobs pesados a la vez.
*   **Soluci√≥n:**
    1.  Verificar que `AIRFLOW__CORE__PARALLELISM` est√© en `2` en `.env`.
    2.  Reducir `SPARK_EXECUTOR_MEMORY` a `3g` temporalmente.

### Error: `GCS 403 Forbidden`
*   **S√≠ntoma:** "Access Denied" al intentar escribir en el bucket.
*   **Causa:** La cuenta de servicio de la VM perdi√≥ permisos o el token expir√≥.
*   **Soluci√≥n:**
    1.  Verificar permisos de la VM: `gcloud compute instances describe airflow-server-prod`
    2.  Asegurar que el scope `storage-rw` est√© activo.

### Error: `Parquet Column Type Mismatch`
*   **S√≠ntoma:** Spark falla leyendo Bronze.
*   **Causa:** Alguien cambi√≥ un tipo de dato en Supabase (ej: `int` a `float`) y rompi√≥ el esquema hist√≥rico.
*   **Soluci√≥n:**
    1.  Borrar la partici√≥n del d√≠a problem√°tico en GCS Bronze.
    2.  Correr `extract_from_supabase.py` manualmente para ese d√≠a con `schema_casting` forzado.

---

## üìÖ Mantimiento Rutinario

*   **Limpieza de Logs:** Airflow genera muchos logs. Ejecutar cada mes:
    ```bash
    docker exec -it airflow-webserver airflow db clean --days 30
    ```
*   **Actualizaci√≥n de C√≥digo:**
    ```bash
    git pull
    # Si cambiaron DAGs, Airflow los detecta solo.
    # Si cambiaron Jobs de Spark o Dockerfile, reiniciar contenedores.
    docker compose -f docker-compose.prod.yaml build
    docker compose -f docker-compose.prod.yaml up -d
    ```
