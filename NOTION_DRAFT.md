# ğŸ—ï¸ PySpark High-Performance Pipeline
*(Architecture & Documentation)*

> **Status:** ğŸŸ¢ Production Ready
> **Stack:** Python 3.11 | Apache Spark 3.5 | Airflow 2.10 | Google Cloud Platform

---

## 1. ğŸ”­ Arquitectura (Lakehouse)

Este pipeline implementa una arquitectura **Medallion (Bronze/Silver/Gold)** desplegada en **Google Compute Engine** usando Contenedores Docker.

### ğŸ§© Diagrama de Flujo
```mermaid
graph LR
    SRC[Supabase DB] -->|Extract| BRONZE[Lake: Raw (Parquet)]
    BRONZE -->|Spark Clean| SILVER[Lake: Silver (Delta/Parquet)]
    SILVER -->|Spark Agg| GOLD[Lake: Gold (Star Schema)]
    GOLD -->|Load| BQ[BigQuery Warehouse]
    BQ -->|Connect| VIZ[Looker Studio]
```

### ğŸ’§ Capas de Datos
-   **Bronze (Raw):** Datos crudos extraÃ­dos incrementalmente. Particionamiento por fecha de negocio (`last_modified_at`).
-   **Silver (Refined):** Datos limpios, deduplicados y tipados fuertemente. Calidad de datos aplicada (Reglas de negocio).
-   **Gold (Curated):** Modelos dimensionales (Hechos y Dimensiones) listos para BI.

---

## 2. âš¡ Performance Wins ("Historias de Guerra")

> ğŸ’¡ **Logro Principal:** ReducciÃ³n del tiempo de ejecuciÃ³n End-to-End de **32 minutos a < 5 minutos** (700% Boost).

### ğŸš€ OptimizaciÃ³n GCS (Object Storage)
-   **El Problema:** Apache Spark trata a GCS como un sistema de archivos tradicional (POSIX). El mecanismo de "commit" de parquets implica escribir a un temporal y luego "Renombrar". En la nube, **Renombrar = Copiar + Borrar**, lo cual es extremadamente lento para miles de archivos pequeÃ±os.
-   **La SoluciÃ³n:** Implementamos un protocolo de escritura personalizado (`file_utils.py`) que deshabilita el rernombrado costoso cuando detecta el entorno `ENV=cloud`, escribiendo directamente al destino final.

### ğŸ”„ Estrategia de Carga HÃ­brida
-   **El Reto:** Los datos de dimensiones (Donantes, Casos) cambian frecuentemente y necesitamos historia completa.
-   **La SoluciÃ³n:**
    -   **Tablas PequeÃ±as/Medianas (Dimensiones):** Full Load Snapshot en cada ejecuciÃ³n (Garantiza consistencia 100%).
    -   **Tablas Grandes (Hechos):** Carga Incremental basada en High-Watermark (Eficiencia).

---

## 3. ğŸ› ï¸ Stack TecnolÃ³gico

| Componente | TecnologÃ­a | Rol |
| :--- | :--- | :--- |
| **Orquestador** | Apache Airflow 2.10 | GestiÃ³n de dependencias, reintentos y alertas (Slack). |
| **Procesamiento** | PySpark 3.5 | Motor de procesamiento en memoria distribuida. |
| **Storage** | Google Cloud Storage | Data Lake escalable y barato. |
| **Warehouse** | BigQuery | Capa de servicio para consultas SQL rÃ¡pidas. |
| **Infraestructura** | GCE VM (Ubuntu) | Servidor `e2-standard-4` (4 vCPU, 16GB RAM). |
| **Seguridad** | Workload Identity | AutenticaciÃ³n sin llaves JSON (Service Account Attach). |

---

## 4. ğŸ“Š MÃ©tricas Clave

| MÃ©trica | Valor | Notas |
| :--- | :---: | :--- |
| **Registros HistÃ³ricos** | **30,000+** | Donantes, Donaciones, Gastos, Casos. |
| **Latencia Pipeline** | **~4 min** | Desde extracciÃ³n hasta BigQuery. |
| **Volumen Diario** | ~100MB | Escalable a TBs sin cambios de cÃ³digo. |
| **Costo Operativo** | **Bajo** | Uso de VM volÃ¡til + Storage Coldline. |

---

## 5. ğŸ“˜ Runbook (Operaciones)

### ğŸš¨ Alertas (Slack)
El pipeline notifica al canal `#data-alerts`:
-   âœ… **Success:** Resumen de tiempos y registros.
-   âŒ **Failure:** Link directo a los logs de Airflow y Tag al equipo.

### ğŸ”„ Disaster Recovery
Si el Lake se corrompe o se necesita reprocesar todo:
1.  Borrar carpeta `checkpoints/watermarks` en GCS.
2.  Trigger DAG manual.
3.  El sistema detecta automÃ¡ticamente "Clean Slate" y reimporta toda la historia.

```bash
# Comando de PÃ¡nico (Reset Total)
gsutil -m rm -r gs://salvando-patitas-spark/checkpoints/*
```
