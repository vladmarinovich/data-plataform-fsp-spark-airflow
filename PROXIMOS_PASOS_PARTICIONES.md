# üîß Pr√≥ximos Pasos: Optimizaci√≥n de Particiones

**Fecha**: 29-Dic-2025  
**Estado Actual**: Autenticaci√≥n GCS ‚úÖ | Particiones ‚ö†Ô∏è Requiere optimizaci√≥n

---

## üéØ PROBLEMA IDENTIFICADO

**Error**: `SQLSTATE: KD009` en jobs de Spark  
**Causa Ra√≠z**: Demasiadas particiones peque√±as (particionamiento por d√≠a desde 2023)  
**Impacto**: Jobs de Silver fallan por Out of Memory al intentar listar cientos de particiones

### **An√°lisis**
```
Particiones actuales: y=YYYY/m=MM/d=DD
Per√≠odo: 2023-01 hasta 2025-12
Total particiones: ~700+ (2 a√±os √ó 365 d√≠as)
Tama√±o promedio: ~50KB por partici√≥n

Problema: Spark intenta listar TODAS las particiones antes de leer
Memoria requerida: Excede los 2.5GB disponibles para el scheduler
```

---

## ‚úÖ SOLUCI√ìN RECOMENDADA

### **Opci√≥n 1: Particionamiento Mensual** (Recomendado)
```
Cambiar de: y=YYYY/m=MM/d=DD
A:          y=YYYY/m=MM

Beneficios:
- Reduce particiones de ~700 a ~24
- Tama√±o por partici√≥n: ~1-2MB (√≥ptimo para Spark)
- Memoria requerida: <500MB
- Compatible con consultas mensuales
```

### **Opci√≥n 2: Sin Particionamiento** (Alternativa)
```
Guardar todo en un solo directorio
Usar columnas de fecha para filtros

Beneficios:
- M√°s simple
- Sin overhead de particiones
- Spark maneja bien archivos de <100MB

Desventaja:
- Menos eficiente para queries con filtros de fecha
```

---

## üìã PASOS PARA IMPLEMENTAR (Pr√≥xima Sesi√≥n)

### **1. Limpiar Bucket GCS** (5 min)
```bash
# Desde tu m√°quina local (con gcloud auth)
gsutil -m rm -r gs://salvando-patitas-spark/lake/raw/
gsutil -m rm -r gs://salvando-patitas-spark/lake/silver/
```

### **2. Modificar Particionamiento en Extract** (10 min)
```python
# Archivo: scripts/extract_from_supabase.py
# L√≠nea ~270-280

# ANTES:
df_partitioned = df.withColumn("y", F.year(date_col).cast("string")) \
                   .withColumn("m", F.lpad(F.month(date_col), 2, "0")) \
                   .withColumn("d", F.lpad(F.dayofmonth(date_col), 2, "0"))

# DESPU√âS:
df_partitioned = df.withColumn("y", F.year(date_col).cast("string")) \
                   .withColumn("m", F.lpad(F.month(date_col), 2, "0"))

# Y cambiar el partitionBy:
.partitionBy("y", "m")  # En lugar de ("y", "m", "d")
```

### **3. Modificar Jobs de Silver** (15 min)
```python
# Archivos: jobs/silver/*.py
# Buscar todas las ocurrencias de:

# ANTES:
df_final = df_final.withColumn("y", F.year("created_at").cast("string")) \
                   .withColumn("m", F.lpad(F.month("created_at"), 2, "0")) \
                   .withColumn("d", F.lpad(F.dayofmonth("created_at"), 2, "0"))

(df_final.write.mode("overwrite")
 .partitionBy("y", "m", "d")  # ‚Üê Cambiar esto
 .parquet(output_path))

# DESPU√âS:
df_final = df_final.withColumn("y", F.year("created_at").cast("string")) \
                   .withColumn("m", F.lpad(F.month("created_at"), 2, "0"))

(df_final.write.mode("overwrite")
 .partitionBy("y", "m")  # ‚Üê Solo a√±o y mes
 .parquet(output_path))
```

**Archivos a modificar**:
- `jobs/silver/donantes.py`
- `jobs/silver/donaciones.py`
- `jobs/silver/gastos.py`
- `jobs/silver/casos.py`
- `jobs/silver/proveedores.py`
- `jobs/silver/hogar_de_paso.py`

### **4. Modificar Jobs de Gold** (10 min)
Similar al paso 3, actualizar particionamiento en:
- `jobs/gold/dim_*.py`
- `jobs/gold/fact_*.py`

### **5. Re-ejecutar Pipeline** (20 min)
```bash
# 1. Trigger DAG desde Airflow UI
# 2. Monitorear logs
# 3. Validar datos en BigQuery
```

---

## üß™ VALIDACI√ìN

### **Checklist Post-Implementaci√≥n**
- [ ] Bucket GCS limpio
- [ ] Extract crea particiones y/m (no y/m/d)
- [ ] Silver lee y escribe con y/m
- [ ] Gold lee y escribe con y/m
- [ ] DAG completa sin errores
- [ ] Datos en BigQuery correctos
- [ ] Memoria de Spark <2GB durante ejecuci√≥n

### **Queries de Validaci√≥n**
```sql
-- BigQuery: Verificar datos
SELECT 
  COUNT(*) as total_donaciones,
  MIN(fecha_donacion) as primera_donacion,
  MAX(fecha_donacion) as ultima_donacion
FROM `salvando-patitas-spark.gold.fact_donaciones`;

-- Debe retornar ~12K registros
```

---

## üìä ESTIMACI√ìN DE MEJORA

### **Antes (Particionamiento Diario)**
```
Particiones: ~700
Memoria Spark: 2.5GB (insuficiente)
Tiempo de listado: ~30s
Estado: ‚ùå FALLA con OOM
```

### **Despu√©s (Particionamiento Mensual)**
```
Particiones: ~24
Memoria Spark: 2.5GB (suficiente)
Tiempo de listado: <1s
Estado: ‚úÖ FUNCIONA
```

**Mejora**: ~30x menos particiones, ~30x m√°s r√°pido

---

## üéì LECCIONES APRENDIDAS

### **1. Particionamiento es Cr√≠tico**
- Demasiadas particiones peque√±as ‚Üí OOM
- Muy pocas particiones grandes ‚Üí Lento
- Sweet spot: 1-10MB por partici√≥n

### **2. Spark Metadata Overhead**
- Spark lista TODAS las particiones antes de leer
- Cada partici√≥n tiene overhead de ~1-2KB en memoria
- 700 particiones √ó 2KB = 1.4MB solo en metadata

### **3. Dise√±o para Escala**
- Pensar en crecimiento futuro
- 2 a√±os de datos diarios = 700 particiones
- 10 a√±os = 3,650 particiones (inmanejable)
- Particionamiento mensual escala mejor

### **4. Trade-offs**
- **Diario**: Mejor para queries de d√≠a espec√≠fico, pero no escala
- **Mensual**: Balance entre granularidad y performance
- **Anual**: Muy grueso, queries lentas
- **Sin particiones**: Simple pero ineficiente para filtros

---

## üí° ALTERNATIVA R√ÅPIDA (Si tienes prisa)

### **Modo Local Temporal**
Si necesitas validar el pipeline YA, puedes:

1. Cambiar `ENV=local` en `docker-compose.yaml`
2. Ejecutar pipeline localmente (sin GCS)
3. Validar que toda la l√≥gica funciona
4. Luego implementar fix de particiones para cloud

**Tiempo**: 10 minutos  
**Ventaja**: Ves resultados inmediatos  
**Desventaja**: No valida integraci√≥n con GCS

---

## ‚úÖ CONCLUSI√ìN

**Estado Actual**:
- ‚úÖ Autenticaci√≥n GCS: RESUELTA
- ‚úÖ Python SDK: FUNCIONANDO
- ‚úÖ Arquitectura: DOCUMENTADA
- ‚ö†Ô∏è Particiones: REQUIERE AJUSTE (no cr√≠tico)

**Pr√≥xima Sesi√≥n** (30-45 min):
1. Limpiar bucket
2. Cambiar particionamiento a y/m
3. Re-ejecutar pipeline
4. Validar en BigQuery
5. ‚úÖ Pipeline 100% funcional

**Recomendaci√≥n**: Descansa hoy, implementa ma√±ana con mente fresca üòä

---

**√öltima actualizaci√≥n**: 2025-12-29 10:32  
**Autor**: Sesi√≥n de debugging con Antigravity  
**Estado**: Listo para implementar
