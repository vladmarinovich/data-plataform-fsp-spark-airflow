# Manual Pipeline Execution

Script para ejecutar el pipeline completo **sin Airflow**, Ãºtil para debugging.

## Uso

```bash
# Ejecutar todo el pipeline
./scripts/run_pipeline.sh

# Ver logs de un job fallido
cat /tmp/pipeline_<job_name>.log
```

## CaracterÃ­sticas

- âœ… **EjecuciÃ³n en orden correcto** (respeta dependencias)
- âœ… **Timeout de 60s por job** (evita cuelgues)
- âœ… **Logs guardados** en `/tmp/pipeline_*.log`
- âœ… **Output con colores** (verde=success, rojo=fail)
- âœ… **ContinÃºa aunque falle** (no se detiene en primer error)
- âœ… **Resumen final** de quÃ© fallÃ³

## Orden de EjecuciÃ³n

1. **Silver** (6 jobs en paralelo lÃ³gico)
2. **Gold Dimensions** (5 jobs)
3. **Gold Facts** (2 jobs)
4. **Gold Features** (3 jobs)
5. **Gold Dashboards** (3 jobs)

## Debugging

Si un job falla:
```bash
# Ver error completo
cat /tmp/pipeline_<nombre_job>.log

# Ejecutar manualmente con mÃ¡s detalle
ENV=local python3 jobs/gold/<job>.py
```

## Ventajas vs Airflow

- ğŸš€ **10x mÃ¡s rÃ¡pido** (sin overhead de Airflow)
- ğŸ” **Errores mÃ¡s claros** (stacktraces directos)
- ğŸ› ï¸ **FÃ¡cil debugear** (logs simples)
- âš¡ **IteraciÃ³n rÃ¡pida** (sin restart de Docker)
