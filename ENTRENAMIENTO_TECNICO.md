# üéì Gu√≠a de Entrenamiento T√©cnico: SPDP Data Platform

Esta gu√≠a est√° dise√±ada para ayudarte a explicar tu proyecto con confianza en entrevistas t√©cnicas o presentaciones de negocio.

---

## 1. El "Elevator Pitch" (La Arquitectura en 1 minuto)

**Pregunta:** *"Cu√©ntame sobre la arquitectura de tu plataforma."*

**Tu Respuesta:**
"He construido un **Data Lakehouse moderno** utilizando la arquitectura Medallion (Bronze, Silver, Gold).
1.  **Ingesta:** Extraigo datos incrementales de PostgreSQL (Supabase) usando Python, guard√°ndolos como Parquet crudo en Google Cloud Storage (**Bronze**).
2.  **Procesamiento:** Utilizo **Apache Spark** orquestado por **Airflow** para limpiar y deduplicar los datos (**Silver**), y luego modelarlos en un esquema Estrella (Star Schema) para anal√≠tica (**Gold**).
3.  **Consumo:** Los datos finales se cargan en **BigQuery** para alimentar dashboards en Looker Studio.
Toda la infraestructura vive en **Docker** sobre una VM de Compute Engine, optimizada para costar menos de $2 USD al mes."

---

## 2. Ingesta: `scripts/extract_from_supabase.py`

**¬øQu√© hace?**
Es el motor de extracci√≥n. Conecta a la base de datos transaccional y descarga los datos nuevos.

**Puntos Clave a Explicar:**
*   **Carga Incremental:** No descargo todo cada vez. Uso una columna `last_modified_at` (Watermark) para traer solo lo que cambi√≥ desde la √∫ltima ejecuci√≥n. *Por qu√©: Eficiencia y velocidad.*
*   **Formato Parquet:** Guardo en Parquet, no CSV. *Por qu√©: Es columnar, comprimido (Snappy) y mantiene los tipos de datos (schema enforcement).*
*   **Particionamiento:** Guardo los archivos en carpetas por fecha (`year=2024/month=01/...`). *Por qu√©: Permite que Spark lea solo lo que necesita (Partition Pruning).*

---

## 3. Orquestaci√≥n: `dags/spdp_main_pipeline.py` (Airflow)

**¬øQu√© hace?**
Es el "director de orquesta". Define el orden de las tareas y maneja los errores.

**Puntos Clave a Explicar:**
*   **DAG (Directed Acyclic Graph):** El flujo va en una sola direcci√≥n. Extracci√≥n -> Silver -> Gold -> BigQuery.
*   **Manejo de Fallos:** Si una tarea falla, Airflow reintenta autom√°ticamente 3 veces. Si falla definitivamente, me env√≠a una alerta a **Slack**.
*   **Recursos (Pools):** Limito la concurrencia a 2 tareas a la vez (`parallelism`). *Por qu√©: Para no saturar la RAM de 16GB de la VM y evitar errores de memoria (OOM).*
*   **Auto-Apagado:** Una tarea final apaga la VM autom√°ticamente. Us√© `trigger_rule='all_done'` para asegurar que se apague incluso si el pipeline falla. *Por qu√©: Ahorro masivo de costos ($500 -> $2).*

---

## 4. Transformaci√≥n: `jobs/silver/*.py` (Spark)

**¬øQu√© hace?**
Limpia los datos crudos. Es la capa de "Calidad".

**Puntos Clave a Explicar:**
*   **Lectura:** Spark lee los Parquet crudos de Bronze.
*   **Deduplicaci√≥n:** Uso `dropDuplicates()` basado en IDs. *Por qu√©: En sistemas distribuidos, a veces se procesa el mismo dato dos veces; esto garantiza unicidad.*
*   **Validaci√≥n de Schema:** Fuerzo los tipos de datos correctos (fechas como fechas, montos como double).
*   **Escritura:** Escribo en la capa Silver particionando por `A√±o/Mes`.

---

## 5. Modelado: `jobs/gold/*.py` (Spark & Kimball)

**¬øQu√© hace?**
Prepara los datos para el negocio. Aqu√≠ aplicamos l√≥gica de negocio, no solo limpieza.

**Puntos Clave a Explicar:**
*   **Modelo Dimensional (Kimball):**
    *   **Tablas de Hechos (Facts):** Eventos que ocurren (ej. `fact_donaciones`, `fact_gastos`). Tienen m√©tricas (dinero) y claves for√°neas.
    *   **Tablas de Dimensiones (Dims):** Contexto (ej. `dim_donantes`, `dim_calendario`). Tienen atributos descriptivos (nombre, ciudad).
*   **Star Schema:** Este dise√±o hace que las consultas en BigQuery sean rapid√≠simas y f√°ciles de entender para los analistas.

---

## 6. Infraestructura & DevOps

**Pregunta:** *"¬øPor qu√© usaste Docker y una VM en lugar de servicios gestionados?"*

**Tu Respuesta:**
"Evalu√© servicios como Cloud Composer o Dataproc, pero su costo base ($300-$500/mes) era excesivo para una ONG.
Al "dockerizar" Airflow y Spark en una sola VM potente (e2-standard-4) y controlarla con scripts de encendido/apagado, logr√© la misma funcionalidad por el 1% del precio. Docker garantiza que el entorno sea reproducible: si corre en mi m√°quina, corre en producci√≥n."

---

## üí° Glosario de Conceptos "Senior" que usaste

Usa estas palabras para sonar muy pro:

*   **Idempotencia:** "Mi pipeline es idempotente; puedo correrlo 10 veces sobre los mismos datos y el resultado final siempre es correcto (no duplica)."
*   **Backfill:** "El dise√±o permite reprocesar historia antigua (Backfill) simplemente borrando la 'watermark'."
*   **Schema Drift:** "Manejo cambios en la estructura de datos forzando esquemas en la capa Silver."
*   **Partition Pruning:** "Optimizo lecturas leyendo solo las particiones de fecha necesarias."

---

## üß™ Ejercicio Pr√°ctico

Abre `jobs/silver/donaciones.py` e intenta explicarme l√≠nea por l√≠nea qu√© est√° pasando, usando los conceptos de arriba.
