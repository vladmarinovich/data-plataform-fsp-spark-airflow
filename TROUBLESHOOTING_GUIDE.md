# üõ†Ô∏è SPDP Data Platform - Troubleshooting Guide & Runbook

Este documento recopila los errores m√°s comunes encontrados durante el desarrollo y operaci√≥n del Data Pipeline (Airflow + Apache Spark + Supabase + GCS) y sus soluciones probadas.

---

## üö® Errores Cr√≠ticos de Spark

### 1. `SparkException: [CANNOT_MERGE_INCOMPATIBLE_DATA_TYPE]`
**S√≠ntoma:** El Job falla al leer la capa `Raw` o `Silver` indicando conflicto entre tipos (ej. `BigInt` y `Double`).
**Causa:**
- Cambio en el esquema de la fuente (Supabase).
- Mezcla de archivos Parquet antiguos (con esquema viejo) y nuevos en la misma carpeta del Data Lake.
- Inferencia de tipos de Spark fallando al leer m√∫ltiples particiones.

**Soluci√≥n (Runbook):**
1.  **Identificar la tabla afectada** (ej. `casos`, `donaciones`).
2.  **Limpiar la carpeta en GCS:**
    ```bash
    gsutil rm -r gs://salvando-patitas-spark/lake/raw/<tabla>/*
    ```
3.  **Resetear Watermark (Opcional):** Si es necesario re-procesar todo el hist√≥rico.
4.  **Ejecutar Airflow:** Clear Task `extract_from_supabase` para iniciar una carga limpia.

---

### 2. `Task received SIGTERM signal` / `TimeoutException`
**S√≠ntoma:** La tarea en Airflow se interrumpe abruptamente o muestra un error de timeout ("Cannot receive any reply...").
**Causa Root:**
- **Recursos Insuficientes:** El contenedor de Docker se qued√≥ sin RAM/CPU (com√∫n en desarrollo local con otras apps abiertas).
- **Latencia de Red:** Spark tard√≥ demasiado listando archivos en GCS debido a una conexi√≥n lenta.
- **Zombie Process:** Un proceso anterior de Spark no muri√≥ bien y bloque√≥ recursos.

**Soluci√≥n:**
1.  **Cerrar aplicaciones pesadas** en el Host (Juegos, IDEs pesados, Chrome tabs).
2.  **Reiniciar Docker:**
    ```bash
    docker-compose down && docker-compose up -d
    ```
3.  **Aumentar recursos:** (Si persiste) Aumentar RAM asignada a Docker Desktop (m√≠nimo 6GB para Spark).
4.  **Migrar a Cloud:** Usar una VM dedicada (e2-standard-4) soluciona esto definitivamente.

---

## üîê Errores de Autenticaci√≥n & Cloud

### 3. `InvalidSignatureError` / `401 Unauthorized` / `Refresh Token`
**S√≠ntoma:** Fallos al acceder a GCS o BigQuery desde dentro del contenedor.
**Causa:**
- Las credenciales ADC (`application_default_credentials.json`) expiraron o rotaron.
- El reloj del sistema (Docker vs Host) est√° desincronizado.

**Soluci√≥n:**
1.  **Refrescar Credenciales en el Host:**
    ```bash
    gcloud auth application-default login
    ```
2.  **Reiniciar contenedores** (para que monten el nuevo archivo JSON).
    ```bash
    docker-compose restart
    ```

---

## üå™Ô∏è Errores de Airflow

### 4. `NameError: name 'XYZ' is not defined`
**S√≠ntoma:** El DAG falla inmediatamente al iniciar una tarea Python.
**Causa:**
- Error en el c√≥digo Python (falta un `import`).
- Airflow Scheduler no ha refrescado el c√≥digo (tiene un delay por defecto).

**Soluci√≥n:**
1.  **Revisar Imports:** Asegurar que todas las variables/m√≥dulos se importan expl√≠citamente.
2.  **Esperar:** Darle 30-60s al Scheduler para detectar cambios.
3.  **Reiniciar Scheduler:** Si se pone terco.

### 5. `DAG scheduling skipped, record locked`
**S√≠ntoma:** El DAG no avanza aunque no haya errores visibles.
**Causa:**
- La base de datos de Airflow (Postgres) se sobrecarg√≥ o reinici√≥, dejando un "lock" en la fila del DAG Run.

**Soluci√≥n:**
- Generalmente **se arregla solo** tras unos minutos.
- Si no, reiniciar el Scheduler (`docker-compose restart airflow-scheduler`).

---

## üèóÔ∏è Decisiones de Arquitectura (Contexto)

### Estrategia de Carga H√≠brida
- **Tablas Fact (Donaciones, Gastos):** Incremental (Watermark) + Append.
- **Tablas Dim (Donantes, Casos):** Incremental Extracci√≥n (Watermark) + **Full Overwrite** Silver (Deduplicaci√≥n).
  * *Por qu√©:* Garantiza la "versi√≥n √∫nica de la verdad" y maneja cambios en dimensiones (SCD Type 1) sin complejidad extra.

---

## ‚òÅÔ∏è Cloud Deployment Day (2026-01-02) - Historias de Guerra

### 6. "Arquitectura Equivocada" (Apple Silicon vs Cloud AMD64)
**S√≠ntoma:** Al levantar Docker en la VM (Ubuntu/AMD64), el error era inmediato: `exec /usr/bin/dumb-init: exec format error`.
**Diagn√≥stico:** La imagen Docker se construy√≥ localmente en un Mac M1/M2/M3 (ARM64). Los procesadores son incompatibles con la VM de Google.
**Soluci√≥n:**
- Implementar pipeline CI/CD con **GitHub Actions** (`.github/workflows/deploy.yml`).
- Configurar el workflow para construir expl√≠citamente para `linux/amd64`.
- Esto automatiza el despliegue y asegura compatibilidad total.

### 7. Permisos de GCS sin JSON (The "No-Key" Challenge)
**S√≠ntoma:** `403 Forbidden` al intentar escribir en el Bucket desde Spark, a pesar de que la VM ten√≠a scope `cloud-platform`.
**Bloqueo:** No se pod√≠an crear llaves JSON por pol√≠tica de organizaci√≥n (`iam.disableServiceAccountKeyCreation`).
**Soluci√≥n Correcta (Workload Identity):**
- En lugar de luchar contra la pol√≠tica o "hackear" llaves inseguras.
- Se otorg√≥ el rol `roles/storage.admin` directamente a la **Cuenta de Servicio de la VM** (`...compute@developer.gserviceaccount.com`).
- Spark detecta autom√°ticamente estas credenciales del entorno (Metadata Server) sin configuraci√≥n extra.

### 8. Airflow Webserver "Crashloop" (Permisos de Disco)
**S√≠ntoma:** `Permission denied: /opt/airflow/logs` o `airflow.cfg`. El contenedor se reiniciaba infinitamente.
**Causa:** Al montar el volumen `.` (directorio actual de la VM) en Docker, el usuario interno del contenedor (`airflow`, uid=1000) no ten√≠a permiso para escribir en la carpeta propiedad del usuario `vladislavmarinovich`.
**Soluci√≥n:**
- **Resetear Due√±o:** `sudo chown -R 1000:0 .` (Darle propiedad al usuario 1000).
- **Permisos Totales:** `sudo chmod -R 777 .` (Soluci√≥n r√°pida y efectiva en este contexto).
- **Limpieza:** `rm -f *.pid *.err` para eliminar bloqueos viejos.

### 9. Acceso Seguro v√≠a T√∫nel SSH
**S√≠ntoma:** La IP p√∫blica no respond√≠a (y es inseguro abrir el puerto 8080 al mundo entero).
**Soluci√≥n:** Port Forwarding v√≠a SSH.
- Comando: `gcloud compute ssh airflow-server-prod ... -- -L 8080:localhost:8080`
- Permite gestionar Airflow desde `http://localhost:8080` de forma segura y encriptada.

---
*√öltima actualizaci√≥n: 02 Enero 2026*

### 10. Performance Bottleneck: Renombrado de Archivos en GCS
**Hallazgo (02-Ene-2026):**
El proceso `silver_donantes` tard√≥ desproporcionadamente m√°s que el resto.
**Causa:**
Al final de cada Job de Spark, ejecutamos `rename_spark_output` para tener un archivo limpio (ej. `donantes.parquet`).
En un sistema local (disco SSD), mover un archivo es instant√°neo (cambio de puntero).
En **Google Cloud Storage (Object Store)**, "renombrar" NO existe. La API hace:
1. **Copiar** el objeto (Download/Upload interno).
2. **Borrar** el original.
Esto a√±ade una sobrecarga de I/O brutal e innecesaria para tablas grandes.

**Acci√≥n Correctiva (Roadmap):**
- **Eliminar `rename_spark_output` en Prod:** Dejar que Spark escriba sus nativos `part-00000-...`. Son perfectamente v√°lidos y ahorran minutos de ejecuci√≥n.
- **Optimizaci√≥n de DAG:** Revisar dependencias para que las tareas pesadas ("Heavy Hitters") como Donantes no bloqueen el flujo cr√≠tico.


### 11.  en 
**S√≠ntoma:** El Job de Spark corre todo bien, escribe los datos, pero se queda pegado o falla al final ("Renombrando archivos...").
**Causa:**
El script `file_utils.py` usa `google.cloud.storage.Client()` para renombrar archivos.
Esta librer√≠a de Python **requiere credenciales expl√≠citas** (ADC) y no siempre hereda autom√°ticamente el contexto de Hadoop/Spark.
Si no encuentra credenciales, puede quedarse buscando o fallar tras un timeout largo.

**Soluci√≥n:**
Asegurarse que la librer√≠a `google-cloud-storage` tenga acceso a las credenciales de la VM.
Como ya dimos permisos IAM a la Service Account de la VM, esto *deber√≠a* funcionar si la librer√≠a detecta el Metadata Server.
Si falla, es mejor **deshabilitar el renombrado** en Cloud, ya que es una operaci√≥n costosa (Copy+Delete).

