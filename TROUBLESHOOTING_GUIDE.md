# üõ†Ô∏è SPDP Data Platform - Troubleshooting Guide & Runbook

Este documento recopila los errores m√°s comunes encontrados durante el desarrollo y operaci√≥n del Data Pipeline (Airflow + Apache Spark + Supabase + GCS) y sus soluciones probadas.

---

## üö® Errores Cr√≠ticos de Spark

### 1. `SparkException: [CANNOT_MERGE_INCOMPATIBLE_DATA_TYPE]`
**S√≠ntoma:** El Job falla al leer la capa `Raw` o `Silver` indicando conflicto entre tipos (ej. `BigInt` y `Double`).
**Causa:**
- Cambio en el esquema de la fuente (Supabase).
- Mezcla de archivos Parquet antiguos (con esquema viejo) y nuevos en la misma carpeta del Data Lake.
- Inferencia de tipos de Spark fallando al leer m√∫ltiples particiones.

**Soluci√≥n (Runbook):**
1.  **Identificar la tabla afectada** (ej. `casos`, `donaciones`).
2.  **Limpiar la carpeta en GCS:**
    ```bash
    gsutil rm -r gs://salvando-patitas-spark/lake/raw/<tabla>/*
    ```
3.  **Resetear Watermark (Opcional):** Si es necesario re-procesar todo el hist√≥rico.
4.  **Ejecutar Airflow:** Clear Task `extract_from_supabase` para iniciar una carga limpia.

---

### 2. `Task received SIGTERM signal` / `TimeoutException`
**S√≠ntoma:** La tarea en Airflow se interrumpe abruptamente o muestra un error de timeout ("Cannot receive any reply...").
**Causa Root:**
- **Recursos Insuficientes:** El contenedor de Docker se qued√≥ sin RAM/CPU (com√∫n en desarrollo local con otras apps abiertas).
- **Latencia de Red:** Spark tard√≥ demasiado listando archivos en GCS debido a una conexi√≥n lenta.
- **Zombie Process:** Un proceso anterior de Spark no muri√≥ bien y bloque√≥ recursos.

**Soluci√≥n:**
1.  **Cerrar aplicaciones pesadas** en el Host (Juegos, IDEs pesados, Chrome tabs).
2.  **Reiniciar Docker:**
    ```bash
    docker-compose down && docker-compose up -d
    ```
3.  **Aumentar recursos:** (Si persiste) Aumentar RAM asignada a Docker Desktop (m√≠nimo 6GB para Spark).
4.  **Migrar a Cloud:** Usar una VM dedicada (e2-standard-4) soluciona esto definitivamente.

---

## üîê Errores de Autenticaci√≥n & Cloud

### 3. `InvalidSignatureError` / `401 Unauthorized` / `Refresh Token`
**S√≠ntoma:** Fallos al acceder a GCS o BigQuery desde dentro del contenedor.
**Causa:**
- Las credenciales ADC (`application_default_credentials.json`) expiraron o rotaron.
- El reloj del sistema (Docker vs Host) est√° desincronizado.

**Soluci√≥n:**
1.  **Refrescar Credenciales en el Host:**
    ```bash
    gcloud auth application-default login
    ```
2.  **Reiniciar contenedores** (para que monten el nuevo archivo JSON).
    ```bash
    docker-compose restart
    ```

---

## üå™Ô∏è Errores de Airflow

### 4. `NameError: name 'XYZ' is not defined`
**S√≠ntoma:** El DAG falla inmediatamente al iniciar una tarea Python.
**Causa:**
- Error en el c√≥digo Python (falta un `import`).
- Airflow Scheduler no ha refrescado el c√≥digo (tiene un delay por defecto).

**Soluci√≥n:**
1.  **Revisar Imports:** Asegurar que todas las variables/m√≥dulos se importan expl√≠citamente.
2.  **Esperar:** Darle 30-60s al Scheduler para detectar cambios.
3.  **Reiniciar Scheduler:** Si se pone terco.

### 5. `DAG scheduling skipped, record locked`
**S√≠ntoma:** El DAG no avanza aunque no haya errores visibles.
**Causa:**
- La base de datos de Airflow (Postgres) se sobrecarg√≥ o reinici√≥, dejando un "lock" en la fila del DAG Run.

**Soluci√≥n:**
- Generalmente **se arregla solo** tras unos minutos.
- Si no, reiniciar el Scheduler (`docker-compose restart airflow-scheduler`).

---

## üèóÔ∏è Decisiones de Arquitectura (Contexto)

### Estrategia de Carga H√≠brida
- **Tablas Fact (Donaciones, Gastos):** Incremental (Watermark) + Append.
- **Tablas Dim (Donantes, Casos):** Incremental Extracci√≥n (Watermark) + **Full Overwrite** Silver (Deduplicaci√≥n).
  * *Por qu√©:* Garantiza la "versi√≥n √∫nica de la verdad" y maneja cambios en dimensiones (SCD Type 1) sin complejidad extra.

---
*√öltima actualizaci√≥n: Enero 2026*
